# -*- coding: utf-8 -*-
"""infer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i3VwstRhrdQdd8hkynuKhBwLHctZSrID
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# 
# ! pip install torchinfo
# ! pip install -U catalyst
# ! pip install onnx onnxruntime
#

import matplotlib.pyplot as plt
import numpy as np
import torch
from torch import nn
from torch.nn import functional as F
import numpy as np
from PIL import Image
import os
import pickle
import glob
import onnxruntime as ort

from collections import defaultdict
from random import choice

from torchvision import datasets

test_ds = datasets.CIFAR10("./cifar10", train=False, download=True)

import os


# Catalyst uses multiple GPUs via DataParallel, we don't need it for now
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

import errno
import os

try:
    os.mkdir("./imgs")
except OSError as exc:
    if exc.errno != errno.EEXIST:
        raise
    pass

class_names = test_ds.classes
num_classes = len(class_names)
label_to_idx = defaultdict(list)

for i, sample in enumerate(test_ds):
    data, lbl = sample
    label_to_idx[lbl].append(i)

grid_size = (2, int(num_classes / 2 + 0.5))
f, axarr = plt.subplots(*grid_size)
f.set_size_inches(15, 4)

#os.mkdir("./imgs")

for lbl in range(num_classes):
    img, _ = test_ds[choice(label_to_idx[lbl])]
    img.save('./imgs/'+'original_label'+str(lbl)+'.png')
    sample_title = "%s (label=%d)" % (class_names[lbl], lbl)
    axarr[lbl % grid_size[0], lbl // grid_size[0]].imshow(img)
    axarr[lbl % grid_size[0], lbl // grid_size[0]].set_title(sample_title)
    axarr[lbl % grid_size[0], lbl // grid_size[0]].axis("off")

# let's use ImageNet mean and std values for image pixel values
means = np.array((0.4914, 0.4822, 0.4465))
stds = np.array((0.2023, 0.1994, 0.2010))

from torchvision import datasets, transforms


base_transforms = [transforms.ToTensor(), transforms.Normalize(means, stds)]
augmented_transforms = [
    # add your own augmentations here
    transforms.RandomCrop(32, padding=4, padding_mode="reflect"),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(hue=0.01, brightness=0.3, contrast=0.3, saturation=0.3),
]
augmented_transforms += base_transforms

transform_basic = transforms.Compose(base_transforms)
#img_tensor = transform_basic(image)
#transform_augment = transforms.Compose(augmented_transforms)

file_path = './imgs/'
imgs_list= glob.glob(file_path + '*.png')

to_infer_batch = []

for i in imgs_list:
    image = Image.open(i)
    transform_basic = transforms.Compose(base_transforms)
    img_tensor = transform_basic(image)
    to_infer_batch.append(img_tensor)
to_infer_batch = torch.stack(to_infer_batch)

img_tensor = transform_basic(image).to(device)

def to_numpy(tensor):
    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()

def softmax_function(x):
    e = np.exp(x)
    return e / e.sum()

# ONNX 런타임에서 계산된 결과값
ort_session = ort.InferenceSession("model_convert.onnx")

ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(to_infer_batch)}
ort_outs = ort_session.run(None, ort_inputs)

img_out_y = ort_outs[0]
softmaxed_y = softmax_function(img_out_y)
predictions = np.argmax(softmax_function(img_out_y), 1)
#ONNX 런타임과 PyTorch에서 연산된 결과값 비교
#np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)

class_labels = {
    0: 'airplane', 
    1: 'automobile', 
    2: 'bird', 
    3: 'cat', 
    4: 'deer', 
    5: 'dog', 
    6: 'frog', 
    7: 'horse', 
    8: 'ship', 
    9: 'truck'}

label_names = []
for i in predictions:
     name = class_labels.get(i)
     label_names.append(name)

import yaml

merged_list = list(zip(imgs_list, label_names))

predictions = {name: value for name, value in zip(imgs_list, label_names)}
print(predictions)

with open('predictions.yaml', 'w') as f:
        yaml.dump(predictions, f)